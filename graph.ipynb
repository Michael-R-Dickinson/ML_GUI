{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import abc\n",
    "\n",
    "import operator\n",
    "from queue import Queue\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# consoleHandler = logging.StreamHandler()\n",
    "# consoleHandler.setLevel(logging.DEBUG)\n",
    "open ('outputs.log', 'w').close()\n",
    "fileHandler = logging.FileHandler('outputs.log', mode='w')\n",
    "fileHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fileHandler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fileHandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vertex: \n",
    "    def __init__(self, dests:list = [], data = None):\n",
    "        self.data = data\n",
    "        self.dests = dests\n",
    "    \n",
    "    def add_dest (self, dest):\n",
    "        assert dest not in self.dests\n",
    "        assert self not in dest.srcs.srcs\n",
    "        self.dests.append (dest)\n",
    "        self.dest.srcs.append (self)\n",
    "        \n",
    "    def remove_edge (self, dest):\n",
    "        if dest in self.dests: \n",
    "            self.dests.remove (dest)\n",
    "        \n",
    "class FlowchartNode (Vertex):\n",
    "    def __init__ (self, position:list, label:str = 'layer', dests:list = [], srcs:list = []):\n",
    "        self.dests = dests\n",
    "        self.srcs = srcs\n",
    "        self.position = position\n",
    "        \n",
    "        self.torchComponent = None\n",
    "        self.label = label\n",
    "        \n",
    "        if all ([isinstance (dest, FlowchartNode) for dest in dests]):\n",
    "            self.dests = dests\n",
    "        \n",
    "        else:\n",
    "            raise ValueError ('Destinations of FlowchartNode must be of the same class')\n",
    "    \n",
    "    # def set_torch_component (self, module: str, size):\n",
    "    #     self.torchComponent = TorchComponent (module, size)\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        return 'FlowchartNode(position={}, label={}, dests={}, srcs={}'.format(\n",
    "            self.position, self.label, ', '.join([d.label for d in self.dests]),\n",
    "            ', '.join([s.label for s in self.srcs])\n",
    "        )\n",
    "        \n",
    "class NodeGroup:\n",
    "    def __init__ (self, nodes): \n",
    "        self.nodes = nodes\n",
    "        \n",
    "    def move (self, x=0, y=0):\n",
    "        for node in self.nodes:\n",
    "            node.position[0] += x\n",
    "            node.position[1] += y\n",
    "\n",
    "\n",
    "class FlowchartGraph:\n",
    "    def __init__(self):\n",
    "        self.startNode = FlowchartNode ([0, 0])\n",
    "        \n",
    "    @classmethod\n",
    "    def fromDict (cls, inpDict, startNode, endNode, torchComponentsDict={}):\n",
    "        f = cls ()\n",
    "        \n",
    "        nodes = {label:deepcopy(FlowchartNode ([i, i], label=label)) for i, label in enumerate(inpDict.keys())}\n",
    "        # for label, dests in inpDict.items():\n",
    "        #     print (f'{label=} {dests=}')\n",
    "        #     for dest in dests:\n",
    "        #         nodes[label].dests.append(nodes[dest])\n",
    "        #         print (f'adding {dest} to {label}')\n",
    "        #         nodes[dest].srcs.append (nodes[label])\n",
    "        #         print (f'adding to src {label} to {dest}')\n",
    "        \n",
    "        # for label, node in nodes.items():\n",
    "        #     # node.dests.extend ([nodes[dest] for dest in inpDict[label]])\n",
    "        #     for destLabel in inpDict [label]:\n",
    "        #         print (f'{destLabel=}, {label=}')\n",
    "        #         cls.addEdge (node, nodes[destLabel])\n",
    "        \n",
    "        for label, dests in inpDict.items():\n",
    "            # print (f'{label=} {dests=}')\n",
    "            for dest in dests:\n",
    "                cls.addEdge (nodes[label], nodes[dest])\n",
    "                # print (f'{nodes[label].label} dest: {nodes[dest].label}')\n",
    "                # print (f'{label=} {nodeLabels(nodes[label])}')\n",
    "\n",
    "        for label, component in torchComponentsDict.items():\n",
    "            nodes[label].torchComponent = component\n",
    "        \n",
    "        f.startNode = nodes[startNode]\n",
    "        f._endNode = nodes[endNode]\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    @property\n",
    "    def endNode (self):\n",
    "        assert hasattr(self, '_endNode'), 'call setEndNode to define '\\\n",
    "                                        + 'output point, necessary before '\\\n",
    "                                        + 'certain methods'\n",
    "                                        \n",
    "        return self._endNode\n",
    "    \n",
    "    def setEndNode (self, node:FlowchartNode):\n",
    "        assert isinstance(node, FlowchartNode)\n",
    "        self._endNode = node\n",
    "        \n",
    "    def searchGraph (self, **kwargs):\n",
    "        visited = []\n",
    "        results = []\n",
    "        q = list()\n",
    "        q.append (self.startNode)\n",
    "        while q:\n",
    "            s = q.pop (0)\n",
    "            if s in visited:\n",
    "                continue\n",
    "            visited.append (s)\n",
    "            \n",
    "            if all (getattr(s, attr)==query for attr, query in kwargs.items()): \n",
    "                results.append (s)\n",
    "            for dest in s.dests:\n",
    "                q.append (dest)\n",
    "                \n",
    "        return results\n",
    "\n",
    "\n",
    "    def graphView (self):\n",
    "        excecuteOrder = self.generateExcecutionOrder()\n",
    "        # excecuteOrderLength = max(list(excecuteOrder.keys()))\n",
    "        return str('\\n'.join ([\n",
    "            'Index: {}: {}'.format (\n",
    "                len(excecuteOrder)-index, \n",
    "                 ', '.join ([node.label for node in nodes])) \n",
    "            for index, nodes in excecuteOrder.items()\n",
    "        ]))\n",
    "        \n",
    "    def generateExcecutionOrder (self):\n",
    "        excOrder = {}\n",
    "        \n",
    "        q = list()\n",
    "        q.append (self.endNode)\n",
    "        \n",
    "        while q:\n",
    "            dequed = q.pop(0)\n",
    "            if all (node in excOrder for node in dequed.dests):\n",
    "                excOrder[dequed] = max ([-1] + [excOrder[dest] for dest in dequed.dests])+1\n",
    "                \n",
    "                for srcNode in dequed.srcs:\n",
    "                    q.append (srcNode)\n",
    "                    \n",
    "        sortedExcOrder = defaultdict (list)\n",
    "        for node, order in (excOrder.items()):\n",
    "            sortedExcOrder[order].append (node)\n",
    "        return dict(sorted(sortedExcOrder.items(), reverse=True))\n",
    "        \n",
    "    def compileTorchGraph (self, input_dim):\n",
    "        self.initialize_torch_components (input_dim)\n",
    "        return TorchGraph (self.startNode, self.endNode, self.generateExcecutionOrder())\n",
    "        \n",
    "    def initialize_torch_components (self, input_dim):\n",
    "        q = list()\n",
    "        self.startNode.torchComponent.initialize_torch(input_dim)\n",
    "        q.extend (self.startNode.dests)\n",
    "        while q:\n",
    "            dequed = q.pop(0)\n",
    "            for destNode in dequed.dests:\n",
    "                q.append (destNode)\n",
    "            \n",
    "            srcs = dequed.srcs\n",
    "            assert all (srcs[0].torchComponent.output_dim == src.torchComponent.output_dim for src in srcs)\n",
    "            dequed.torchComponent.initialize_torch (srcs[0].torchComponent.output_dim)\n",
    "    \n",
    "    # @property\n",
    "    # def model (self):\n",
    "    #     if not hasattr(self.model, '_model'):\n",
    "    #         raise ValueError ('Graph must be compiled before accessing model')\n",
    "    #     return self._model\n",
    "    \n",
    "    @staticmethod\n",
    "    def addEdge (src, dest): \n",
    "        assert (dest not in src.dests) and (src not in dest.srcs), \\\n",
    "            f'cannot add edge; duplicate connection {src.label=}, {dest.label=}'\n",
    "            \n",
    "        src.dests.append (dest)\n",
    "        dest.srcs.append (src)\n",
    "    \n",
    "    @classmethod\n",
    "    def countNodes (cls, node, visited=[]):\n",
    "        destsCount = []\n",
    "        for dest in node.dests:\n",
    "            if dest not in visited:\n",
    "                visited.append(dest)\n",
    "                destsCount.append(cls.countNodes(dest, visited))\n",
    "            \n",
    "        return sum(destsCount)+1\n",
    "    \n",
    "    @classmethod\n",
    "    def maxDepth (cls, node):\n",
    "        if node is None:\n",
    "            return -1\n",
    "        \n",
    "        else:\n",
    "            return max ([0] + [\n",
    "                    cls.maxDepth(node) \n",
    "                    for node in node.dests\n",
    "                ])+1  \n",
    "        \n",
    "    def __str__ (self):\n",
    "        return self.graphView()      \n",
    "\n",
    "\n",
    "    def __repr__ (self):\n",
    "        return (\n",
    "            'FlowchartGraph(nodes: {}, depth: {})'\n",
    "                .format (\n",
    "                    self.countNodes(self.startNode), \n",
    "                    self.maxDepth(self.startNode)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "class TorchComponent (nn.Module):\n",
    "    nessisary_params = {'example':type}\n",
    "        \n",
    "    # @abc.abstractmethod\n",
    "    def __init__ (self, ) -> None:\n",
    "        \"\"\" Saves params and calculates output variable \n",
    "            Should verify that all nessisary_inputs are in inputs\n",
    "            Vars:\n",
    "                self.output_dim (int): dimension of the layer's output\n",
    "                self.initialized (bool): False\n",
    "            \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def verify_inputs (self):\n",
    "        if not set(self.params.keys()) == set(self.nessisary_params.keys()):\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def initialize_torch (self, input_dim) -> None:\n",
    "        \"\"\" Initializes a torch module with params\n",
    "            Sets self.initializd = True\n",
    "            Inputs:\n",
    "                input_dim (int): dimension of the input layer's output\n",
    "                                \n",
    "        \"\"\"\n",
    "        return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def forward (self, batch) -> torch.tensor:\n",
    "        \"\"\" Runs the module and returns the output . \n",
    "            Must be called after self.initialize_torch\n",
    "            \n",
    "            Inputs: \n",
    "                batch (torch.Tensor): output from previous layer\n",
    "                \n",
    "            Returns:\n",
    "                (torch.Tensor): layer output\n",
    "            \n",
    "        \"\"\"\n",
    "        return\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        return f'{type(self).__name__}(initialized: {self.initialized}, output_dim: {self.output_dim})'\n",
    "    \n",
    "class LinearComponent (TorchComponent):\n",
    "    # nessisary_params = {'size':int, 'num_layers':int}\n",
    "    \n",
    "    def __init__ (self, size, num_layers=1):      \n",
    "        \"\"\"  \n",
    "        Args: \n",
    "            size: int,\n",
    "            num_layers: int\n",
    "        \n",
    "        Vars:\n",
    "            self.params (dict): paramaters to build torch module with\n",
    "            self.output_dim (int): dimension of the layer's output\n",
    "            self.initialized (bool): False\n",
    "\n",
    "        \"\"\"\n",
    "  \n",
    "        # if self.verify_inputs (params) == False:\n",
    "        #     raise ValueError ('params did not contain all nessisary_params')\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = size\n",
    "        \n",
    "        self.initialized = False\n",
    "        \n",
    "        \n",
    "    def initialize_torch (self, input_dim): \n",
    "        self.input_dim = True\n",
    "        self.linear_modules = nn.ModuleList (\n",
    "            [\n",
    "                nn.Linear (input_dim, self.output_dim),\n",
    "                *[\n",
    "                    nn.Linear(self.output_dim, self.output_dim) \n",
    "                    for i in range (self.num_layers-1)\n",
    "                ]\n",
    "            ])\n",
    "        \n",
    "        # self.weight = nn.Parameter (torch.FloatTensor (self.output_dim, input_dim))\n",
    "        # nn.init.xavier_uniform_(self.weight)\n",
    "        # self.linear_test_layer = nn.Linear (input_dim, self.output_dim)\n",
    "        \n",
    "        # logging.debug (f'Initialized Linear Layer with input_size {input_dim}')\n",
    "            \n",
    "    def forward (self, batch):\n",
    "        batch = batch.float()\n",
    "\n",
    "        logger.debug (f'batch type= {batch.dtype}, {batch.shape=}')\n",
    "        for i, layer in enumerate (self.linear_modules):\n",
    "            logger.debug (f'starting linear layer {i} with batch type {batch.dtype}, size {batch.shape}')\n",
    "            batch = layer (batch)\n",
    "        \n",
    "        # batch = self.linear_test_layer (batch)\n",
    "        # batch = F.linear (batch, self.weight)\n",
    "\n",
    "        logger.debug ('linear layer forward pass complete')\n",
    "        \n",
    "        return [batch]\n",
    "                    \n",
    "        \n",
    "inpDict = {\n",
    "    'a':['b','c'],\n",
    "    'b':['d'],\n",
    "    'c':['d'],\n",
    "    'd':[]\n",
    "}\n",
    "\n",
    "inpDict = {\n",
    "    'a':['b','c'],\n",
    "    'b':['d'],\n",
    "    'c':['e'],\n",
    "    'd':['e'],\n",
    "    'e':['f'],\n",
    "    'f':[]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "g = FlowchartGraph.fromDict (inpDict, 'a', 'f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.setEndNode(g.searchGraph (label='f')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [FlowchartNode(position=[0, 0], label=a, dests=b, c, srcs=],\n",
       " 3: [FlowchartNode(position=[1, 1], label=b, dests=d, srcs=a],\n",
       " 2: [FlowchartNode(position=[2, 2], label=c, dests=e, srcs=a,\n",
       "  FlowchartNode(position=[3, 3], label=d, dests=e, srcs=b],\n",
       " 1: [FlowchartNode(position=[4, 4], label=e, dests=f, srcs=c, d],\n",
       " 0: [FlowchartNode(position=[5, 5], label=f, dests=, srcs=e]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.generateExcecutionOrder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1: a\n",
      "Index: 2: b\n",
      "Index: 3: c, d\n",
      "Index: 4: e\n",
      "Index: 5: f\n"
     ]
    }
   ],
   "source": [
    "print (g.graphView())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchGraph (pl.LightningModule):\n",
    "    default_criterions = {\n",
    "        'binary': nn.BCELoss,\n",
    "        'regression':nn.MSELoss,\n",
    "        'multiclass':nn.CrossEntropyLoss\n",
    "        \n",
    "    }\n",
    "    \n",
    "    available_metrics = {\n",
    "        'accuracy': {\n",
    "            'criterion': metrics.accuracy_score,\n",
    "            'kwargs': {}, \n",
    "            'optimization_operator': operator.gt\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__ (self, startNode, endNode, excecutionOrder):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.assembled = False\n",
    "        self.startNode = startNode\n",
    "        self.endNode = endNode\n",
    "        self.excecutionOrder = excecutionOrder\n",
    "        \n",
    "        self.startNode.srcs = ['inputs']\n",
    "        \n",
    "        self.best_metric_scores = defaultdict (dict)\n",
    "        self.saved_min_loss = np.inf\n",
    "        \n",
    "        self.selected_metrics = {}\n",
    "    \n",
    "    def add_metric (self, metrics: list[str] | str):\n",
    "        if isinstance(metrics, str):\n",
    "            metrics = [metrics]\n",
    "            \n",
    "        for metric in metrics:\n",
    "            if metric not in self.available_metrics:\n",
    "                continue\n",
    "            \n",
    "            self.selected_metrics[metric] = self.available_metrics[metric]\n",
    "            \n",
    "            \n",
    "    @property\n",
    "    def criterion (self):\n",
    "        if not hasattr(self, '_criterion'):\n",
    "            self._criterion = self.get_criterion()()\n",
    "        return self._criterion\n",
    "    \n",
    "    @criterion.setter\n",
    "    def criterion (self, criterion):\n",
    "        self._criterion = criterion\n",
    "    \n",
    "    def get_criterion (self):\n",
    "        if self.endNode.torchComponent.output_dim > 1:\n",
    "            return self.default_criterions['multiclass']\n",
    "        \n",
    "        else:\n",
    "            return self.default_criterions['regression']\n",
    "        \n",
    "    \n",
    "        \n",
    "                            \n",
    "    def forward (self, *args, labels=None):\n",
    "        # assert self.assembled == True, 'torch must be assembled ' +\\\n",
    "        #                                'before calling forward'\n",
    "        nodeOutputs = {'inputs':args}\n",
    "        \n",
    "        for order, nodes in self.excecutionOrder.items():\n",
    "            for node in nodes: \n",
    "                inputs = []\n",
    "                for src in node.srcs:\n",
    "                    inputs.extend (nodeOutputs[src]) \n",
    "                    \n",
    "                # logger.debug (f'{len(inputs)=}, {type(inputs[0])}, {inputs[0].shape=}')\n",
    "                \n",
    "                nodeOutputs[node] = node.torchComponent (*inputs)\n",
    "                \n",
    "                # nodeOutputs[node] = node.torchComponent (\n",
    "                #     *[nodeOutputs[src] for src in node.srcs]\n",
    "                # )\n",
    "        outputs = nodeOutputs[self.endNode][0]\n",
    "        \n",
    "        if self.endNode.torchComponent.output_dim == 1:\n",
    "            outputs = torch.squeeze (outputs)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            labels = labels.type (torch.float32)\n",
    "            logger.debug (f'{self.criterion=}, {outputs.shape=}, {labels.shape=}, {outputs.dtype}, {labels.dtype}')\n",
    "            loss = self.criterion (outputs, labels)\n",
    "        \n",
    "        return loss, outputs\n",
    "    \n",
    "    def configure_optimizers (self):\n",
    "        return torch.optim.Adam(self.parameters, lr=1e-3)\n",
    "    \n",
    "    def _step (self, batch, step_type):\n",
    "        src, trg = batch\n",
    "        loss, out = self (src, labels=trg)\n",
    "        self.log('loss/{}'.format(step_type), loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {'loss': loss, 'y_hat': out, f'labels': trg}\n",
    "    \n",
    "    def training_step (self, batch, batch_idx):\n",
    "        values = self._step (batch, 'train')\n",
    "        return values\n",
    "    \n",
    "    def validation_step (self, valid_batch, batch_idx):\n",
    "        values = self._step (valid_batch, 'valid')\n",
    "        return values\n",
    "        \n",
    "    def test_step (self, test_batch, batch_idx):\n",
    "        values = self._step (test_batch, 'test')\n",
    "        return values\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.log_metrics(outputs, 'train')\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log_metrics(outputs, 'valid')\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        self.log_metrics(outputs, 'test')\n",
    "\n",
    "\n",
    "    def log_metrics (self, outputs, step_type):\n",
    "        \"\"\" Logs metrics defined in self.selected_metrics\n",
    "        \n",
    "        format of selected_metrics:\n",
    "            Dict: {\n",
    "                name: str,\n",
    "                metric: Dict {\n",
    "                    criterion: function (out, trg, kwargs)\n",
    "                    kwargs: any extra key word arguments \n",
    "                            to be passed into criterion\n",
    "                    optimization_operator: function (int, int) \n",
    "                                           simply an operator such as lt or gt\n",
    "                                           defines which argument should be saved\n",
    "                                           to self.best_metric_scores\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        labels, preds = [], []\n",
    "\n",
    "        for output in outputs:\n",
    "            labels.extend (output[\"labels\"].detach().cpu())\n",
    "            preds.extend (output[\"y_hat\"].detach().cpu())\n",
    "            \n",
    "            # for out_labels in output[\"labels\"].detach().cpu():\n",
    "            #     labels.append(out_labels)\n",
    "            # for out_predictions in output[\"y_hat\"].detach().cpu():\n",
    "            #     preds.append(out_predictions)\n",
    "\n",
    "        labels = torch.stack(labels).int()\n",
    "        preds = torch.stack(preds)\n",
    "        \n",
    "        \n",
    "        for name, metric, in self.selected_metrics.items():\n",
    "            metric_score = metric['criterion'] (preds, labels, **metric['kwargs'])\n",
    "            \n",
    "            if metric['optimization_operator'] (metric_score, self.best_metric_scores [step_type][name]):\n",
    "                self.best_metric_scores [step_type][name] = metric_score\n",
    "                \n",
    "            self.log ('{}/{}'.format(name, step_type), metric_score)\n",
    "            self.log('best {}/{}'.format(name, step_type),\n",
    "                     self.saved_metric_scores[step_type][name])\n",
    "        self.log (f'min_loss/{step_type}', self.min_loss (torch.stack(*(d['loss'] for d in outputs)).mean()))\n",
    "        \n",
    "    def min_loss (self, loss):\n",
    "        if loss < self.saved_min_loss:\n",
    "            self.saved_min_loss = loss\n",
    "        return self.saved_min_loss\n",
    "        \n",
    "    \n",
    "class WineDataset (Dataset):\n",
    "    def __init__ (self, data, datasetPercent: float=None):\n",
    "        self.datasetPercent = datasetPercent\n",
    "        \n",
    "        self.src = data.loc [:, data.columns != 'quality']\n",
    "        self.trg = data.loc [:, 'quality']\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        return [\n",
    "            torch.tensor (self.src.iloc[idx]), \n",
    "            torch.tensor (self.trg.iloc[idx])\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.src) == len(self.trg)\n",
    "        return len(self.trg)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'WineDataset ({self.datasetPercent*100}% of full dataset)'\n",
    "\n",
    "\n",
    "class WineDataModule (pl.LightningModule):\n",
    "    def __init__ (self, dataPath, splits = [float,], batch_size = 32, shuffle=False, num_workers=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.dataPath = dataPath\n",
    "        self.splits = splits\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def setup (self, stage: str = None):\n",
    "        dataset = pd.read_csv (self.dataPath, delimiter=';')\n",
    "        \n",
    "        assert len (self.splits) == 3, ValueError ('Splits must be of length 3: trainset, validset, testset')\n",
    "        splits = self.split_data (dataset, self.splits)\n",
    "        self.trainset, self.validset, self.testset = self.build_datasets (splits)\n",
    "        \n",
    "    def build_datasets (self, splits):\n",
    "        return [\n",
    "            WineDataset (\n",
    "                split['dataset'], \n",
    "                datasetPercent=split['split_percent']\n",
    "            ) for split in splits\n",
    "        ]\n",
    "        \n",
    "    def split_data (self, dataset, splits):\n",
    "        datasets = list()\n",
    "        dataLen = len(dataset)\n",
    "        \n",
    "        prev = 0\n",
    "        for i, split in enumerate(splits): \n",
    "            prev = int(sum (splits[:i])*dataLen)\n",
    "            datasets.append (\n",
    "                {\n",
    "                    'dataset':dataset[prev:prev+int(dataLen*split)-1],\n",
    "                    'split_percent':split\n",
    "                 }\n",
    "            )\n",
    "            \n",
    "        return datasets\n",
    "        \n",
    "    def train_dataloader (self):\n",
    "        return DataLoader (\n",
    "            self.trainset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "            )\n",
    "    \n",
    "    def val_dataloader (self):\n",
    "        return DataLoader (\n",
    "            self.validset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "            )\n",
    "    \n",
    "    def test_dataloader (self):\n",
    "        return DataLoader (\n",
    "            self.testset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "            )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = r'C:\\Code\\ML_GUI\\winequality-white.csv'\n",
    "df = pd.read_csv (dataPath, delimiter =';')\n",
    "\n",
    "# x = WineDataset (df, 1)\n",
    "# dl = DataLoader (x, batch_size = 32)\n",
    "\n",
    "dm = WineDataModule (dataPath, [0.8, 0.1, 0.1], batch_size = 32)\n",
    "dm.setup()\n",
    "dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    print (batch[0].shape)\n",
    "    print (batch[1].shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1: Linear1\n",
      "Index: 2: Linear2\n"
     ]
    }
   ],
   "source": [
    "inpDict = {\n",
    "    'Linear1':['Linear2'],\n",
    "    'Linear2':[]\n",
    "}\n",
    "\n",
    "torchComponentsDict = {\n",
    "    'Linear1': LinearComponent (size=24, num_layers=2),\n",
    "    'Linear2': LinearComponent (size=1, num_layers=1)\n",
    "}\n",
    "\n",
    "g = FlowchartGraph.fromDict (inpDict, 'Linear1', 'Linear2', torchComponentsDict)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = g.compileTorchGraph(dm.trainset.src.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.criterion = nn.L1Loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, out = graph (batch[0], labels = batch[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Profile_SI-env",
   "language": "python",
   "name": "profile_si-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc280a84aced117807f9d1d97bbb98e839ace61c7335532f3307a7575a63b2a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
